version: 1.0.3
cache: true
# fileStrategy: "firebase"  # If using Firebase CDN
 # fileConfig:
 #   endpoints:
 #     assistants:
 #      fileLimit: 5
 #      fileSizeLimit: 100  # Maximum size for an individual file in MB
 #      totalSizeLimit: 300  # Maximum total size for all files in a single request in MB
 #    openAI:
 #      fileSizeLimit: 10  # Disables file uploading to the OpenAI endpoint
 #    default:
 #      totalSizeLimit: 20
 #  serverFileSizeLimit: 100  # Global server file size limit in MB
 #  avatarSizeLimit: 2  # Limit for user avatar image size in MB
# rateLimits:
 # fileUploads:
 #   ipMax: 100
 #   ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
 #   userMax: 50
 #   userWindowInMinutes: 60  # Rate limit window for file uploads per user
# registration:
#  socialLogins: ["google", "facebook", "github", "discord", "openid"]

speech:
  tts:
    openai:
      apiKey: '${TTS_API_KEY}'
      model: 'tts-1'
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
 
  stt:
    openai:
      apiKey: '${STT_API_KEY}'
      model: 'whisper-1'

  speechTab:
    conversationMode: true
    advancedMode: true
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true

fileConfig:
  endpoints:
    default:
      fileLimit: 5
      fileSizeLimit: 5
      totalSizeLimit: 15



endpoints:
  assistants:
    disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
    pollIntervalMs: 750  # Polling interval for checking assistant updates
    timeoutMs: 180000  # Timeout for assistant operations
    privateAssistants: true
    # Should only be one or the other, either `supportedIds` or `excludedIds`
    # supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
    # excludedIds: ["asst_excludedAssistantId"]
  custom:
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: ["mistral-tiny", "mistral-small", "mistral-medium"]
        fetch: true  # Attempt to dynamically fetch available models
        userIdQuery: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: true
      summaryModel: "mistral-summary"
      forcePrompt: false
      modelDisplayLabel: "Mistral AI"
      addParams:
        safe_prompt: true
      dropParams:
        - "stop"
        - "user"
        - "presence_penalty"
        - "frequency_penalty"
      # headers:
      #    x-custom-header: "${CUSTOM_HEADER_VALUE}"
    # - name: "OpenRouter"
    #   apiKey: "${OPENROUTER_KEY}"
    #   baseURL: "https://openrouter.ai/api/v1"
    #   models:
    #     default: ["nousresearch/nous-capybara-34b","openrouter/auto","nousresearch/nous-capybara-7b","nousresearch/nous-hermes-2-mistral-7b-dpo","google/gemma-7b-it:free","alpindale/goliath-120b","huggingfaceh4/zephyr-7b-beta","openchat/openchat-7b","gryphe/mythomist-7b","openrouter/cinematika-7b","rwkv/rwkv-5-world-3b","recursal/rwkv-5-3b-ai-town","jebcarter/psyfighter-13b","koboldai/psyfighter-13b-2","neversleep/noromaid-mixtral-8x7b-instruct","nousresearch/nous-hermes-llama2-13b","meta-llama/codellama-34b-instruct","phind/phind-codellama-34b","intel/neural-chat-7b","mistralai/mixtral-8x7b-instruct","haotian-liu/llava-13b","nousresearch/nous-hermes-2-vision-7b","meta-llama/llama-2-13b-chat","perplexity/sonar-small-chat","perplexity/sonar-medium-online","perplexity/sonar-medium-chat","perplexity/sonar-small-online","perplexity/sonar-medium-online","mistralai/mistral-large","perplexity/pplx-70b-online","perplexity/pplx-7b-online","perplexity/pplx-7b-chat","perplexity/pplx-70b-chat","meta-llama/llama-2-70b-chat","nousresearch/nous-hermes-llama2-70b","jondurbin/airoboros-l2-70b","migtissera/synthia-70b","teknium/openhermes-2-mistral-7b","teknium/openhermes-2.5-mistral-7b","pygmalionai/mythalion-13b","undi95/remm-slerp-l2-13b","xwin-lm/xwin-lm-70b","gryphe/mythomax-l2-13b-8k","undi95/toppy-m-7b","alpindale/goliath-120b","lizpreciatior/lzlv-70b-fp16-hf","neversleep/noromaid-20b","01-ai/yi-34b-chat","01-ai/yi-34b","01-ai/yi-6b","togethercomputer/stripedhyena-nous-7b","togethercomputer/stripedhyena-hessian-7b","mistralai/mixtral-8x7b","cognitivecomputations/dolphin-mixtral-8x7b","nousresearch/nous-hermes-yi-34b","anthropic/claude-2","anthropic/claude-2.0","anthropic/claude-instant-v1","anthropic/claude-instant-v1-100k","mancer/weaver","open-orca/mistral-7b-openorca","gryphe/mythomax-l2-13b"]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "gpt-3.5-turbo"
    #   summarize: false
    #   forcePrompt: false
    #   modelDisplayLabel: "OpenRouter"
    #   dropParams:
    #     - "stop"
        # OpenRouter.ai
    # Model list: https://openrouter.ai/models
    # Script to fetch models: https://github.com/LibreChat-AI/librechat-config-yaml/blob/main/scripts/openrouter.py
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "openrouter/auto",
          "---FREE---",
          "google/gemma-2-9b-it:free",
          "google/gemma-7b-it:free",
          "gryphe/mythomist-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "meta-llama/llama-3-8b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "mistralai/mistral-7b-instruct:free",
          "nousresearch/nous-capybara-7b:free",
          "openchat/openchat-7b:free",
          "qwen/qwen-2-7b-instruct:free",
          "undi95/toppy-m-7b:free",
          "---NITRO---",
          "google/gemma-7b-it:nitro",
          "gryphe/mythomax-l2-13b:nitro",
          "meta-llama/llama-3-70b-instruct:nitro",
          "meta-llama/llama-3-8b-instruct:nitro",
          "mistralai/mistral-7b-instruct:nitro",
          "mistralai/mixtral-8x7b-instruct:nitro",
          "undi95/toppy-m-7b:nitro",
          "---BETA---",
          "anthropic/claude-2.0:beta",
          "anthropic/claude-2.1:beta",
          "anthropic/claude-2:beta",
          "anthropic/claude-3-haiku:beta",
          "anthropic/claude-3-opus:beta",
          "anthropic/claude-3-sonnet:beta",
          "anthropic/claude-3.5-sonnet:beta",
          "anthropic/claude-instant-1:beta",
          "---EXTENDED---",
          "gryphe/mythomax-l2-13b:extended",
          "meta-llama/llama-3-8b-instruct:extended",
          "neversleep/llama-3-lumimaid-8b:extended",
          "nousresearch/hermes-3-llama-3.1-405b:extended",
          "openai/gpt-4o:extended",
          "undi95/remm-slerp-l2-13b:extended",
          "---01-AI---",
          "01-ai/yi-1.5-34b-chat",
          "01-ai/yi-34b",
          "01-ai/yi-34b-chat",
          "01-ai/yi-6b",
          "01-ai/yi-large",
          "01-ai/yi-large-fc",
          "01-ai/yi-large-turbo",
          "01-ai/yi-vision",
          "---AI21---",
          "ai21/jamba-1-5-large",
          "ai21/jamba-1-5-mini",
          "ai21/jamba-instruct",
          "---ANTHROPIC---",
          "anthropic/claude-1",
          "anthropic/claude-1.2",
          "anthropic/claude-2",
          "anthropic/claude-2.0",
          "anthropic/claude-2.1",
          "anthropic/claude-3-haiku",
          "anthropic/claude-3-opus",
          "anthropic/claude-3-sonnet",
          "anthropic/claude-3.5-sonnet",
          "anthropic/claude-instant-1",
          "anthropic/claude-instant-1.0",
          "anthropic/claude-instant-1.1",
          "---COGNITIVECOMPUTATIONS---",
          "cognitivecomputations/dolphin-llama-3-70b",
          "cognitivecomputations/dolphin-mixtral-8x22b",
          "cognitivecomputations/dolphin-mixtral-8x7b",
          "---COHERE---",
          "cohere/command",
          "cohere/command-r",
          "cohere/command-r-plus",
          "---GOOGLE---",
          "google/gemini-flash-1.5",
          "google/gemini-pro",
          "google/gemini-pro-1.5",
          "google/gemini-pro-1.5-exp",
          "google/gemini-pro-vision",
          "google/gemma-2-27b-it",
          "google/gemma-2-9b-it",
          "google/gemma-7b-it",
          "google/palm-2-chat-bison",
          "google/palm-2-chat-bison-32k",
          "google/palm-2-codechat-bison",
          "google/palm-2-codechat-bison-32k",
          "---META-LLAMA---",
          "meta-llama/codellama-34b-instruct",
          "meta-llama/codellama-70b-instruct",
          "meta-llama/llama-2-13b-chat",
          "meta-llama/llama-2-70b-chat",
          "meta-llama/llama-3-70b",
          "meta-llama/llama-3-70b-instruct",
          "meta-llama/llama-3-8b",
          "meta-llama/llama-3-8b-instruct",
          "meta-llama/llama-3.1-405b",
          "meta-llama/llama-3.1-405b-instruct",
          "meta-llama/llama-3.1-70b-instruct",
          "meta-llama/llama-3.1-8b-instruct",
          "meta-llama/llama-guard-2-8b",
          "---MICROSOFT---",
          "microsoft/phi-3-medium-128k-instruct",
          "microsoft/phi-3-medium-4k-instruct",
          "microsoft/phi-3-mini-128k-instruct",
          "microsoft/phi-3.5-mini-128k-instruct",
          "microsoft/wizardlm-2-7b",
          "microsoft/wizardlm-2-8x22b",
          "---MISTRALAI---",
          "mistralai/codestral-mamba",
          "mistralai/mistral-7b-instruct",
          "mistralai/mistral-7b-instruct-v0.1",
          "mistralai/mistral-7b-instruct-v0.2",
          "mistralai/mistral-7b-instruct-v0.3",
          "mistralai/mistral-large",
          "mistralai/mistral-medium",
          "mistralai/mistral-nemo",
          "mistralai/mistral-small",
          "mistralai/mistral-tiny",
          "mistralai/mixtral-8x22b",
          "mistralai/mixtral-8x22b-instruct",
          "mistralai/mixtral-8x7b",
          "mistralai/mixtral-8x7b-instruct",
          "---NEVERSLEEP---",
          "neversleep/llama-3-lumimaid-70b",
          "neversleep/llama-3-lumimaid-8b",
          "neversleep/noromaid-20b",
          "---NOUSRESEARCH---",
          "nousresearch/hermes-2-pro-llama-3-8b",
          "nousresearch/hermes-2-theta-llama-3-8b",
          "nousresearch/hermes-3-llama-3.1-405b",
          "nousresearch/hermes-3-llama-3.1-70b",
          "nousresearch/nous-capybara-7b",
          "nousresearch/nous-hermes-2-mistral-7b-dpo",
          "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
          "nousresearch/nous-hermes-2-mixtral-8x7b-sft",
          "nousresearch/nous-hermes-llama2-13b",
          "nousresearch/nous-hermes-yi-34b",
          "---PERPLEXITY---",
          "perplexity/llama-3-sonar-large-32k-chat",
          "perplexity/llama-3-sonar-large-32k-online",
          "perplexity/llama-3-sonar-small-32k-chat",
          "perplexity/llama-3-sonar-small-32k-online",
          "perplexity/llama-3.1-sonar-huge-128k-online",
          "perplexity/llama-3.1-sonar-large-128k-chat",
          "perplexity/llama-3.1-sonar-large-128k-online",
          "perplexity/llama-3.1-sonar-small-128k-chat",
          "perplexity/llama-3.1-sonar-small-128k-online",
          "---QWEN---",
          "qwen/qwen-110b-chat",
          "qwen/qwen-14b-chat",
          "qwen/qwen-2-72b-instruct",
          "qwen/qwen-2-7b-instruct",
          "qwen/qwen-32b-chat",
          "qwen/qwen-4b-chat",
          "qwen/qwen-72b-chat",
          "qwen/qwen-7b-chat",
          "---SAO10K---",
          "sao10k/fimbulvetr-11b-v2",
          "sao10k/l3-euryale-70b",
          "sao10k/l3-lunaris-8b",
          "sao10k/l3-stheno-8b",
          "---OTHERS---",
          "aetherwiing/mn-starcannon-12b",
          "allenai/olmo-7b-instruct",
          "alpindale/goliath-120b",
          "alpindale/magnum-72b",
          "austism/chronos-hermes-13b",
          "databricks/dbrx-instruct",
          "deepseek/deepseek-chat",
          "deepseek/deepseek-coder",
          "gryphe/mythomax-l2-13b",
          "gryphe/mythomist-7b",
          "jondurbin/airoboros-l2-70b",
          "lizpreciatior/lzlv-70b-fp16-hf",
          "mancer/weaver",
          "nothingiisreal/mn-celeste-12b",
          "open-orca/mistral-7b-openorca",
          "openchat/openchat-7b",
          "openchat/openchat-8b",
          "openrouter/flavor-of-the-week",
          "phind/phind-codellama-34b",
          "pygmalionai/mythalion-13b",
          "recursal/eagle-7b",
          "recursal/rwkv-5-3b-ai-town",
          "rwkv/rwkv-5-world-3b",
          "snowflake/snowflake-arctic-instruct",
          "sophosympatheia/midnight-rose-70b",
          "teknium/openhermes-2-mistral-7b",
          "teknium/openhermes-2.5-mistral-7b",
          "togethercomputer/stripedhyena-hessian-7b",
          "togethercomputer/stripedhyena-nous-7b",
          "undi95/remm-slerp-l2-13b",
          "undi95/toppy-m-7b",
          "xwin-lm/xwin-lm-70b"
          ]
        fetch: false
      dropParams: ["stop"]
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      summaryModel: "gpt-3.5-turbo"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"
    #groq
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
            'llama3-70b-8192',
            'llama3-8b-8192',
            'llama2-70b-4096',
            'mixtral-8x7b-32768',
            'gemma-7b-it',
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      summarize: false
      summaryModel: "mixtral-8x7b-32768"
      forcePrompt: false
      modelDisplayLabel: "groq"

   
