version: 1.0.3
cache: true
# fileStrategy: "firebase"  # If using Firebase CDN
 # fileConfig:
 #   endpoints:
 #     assistants:
 #      fileLimit: 5
 #      fileSizeLimit: 100  # Maximum size for an individual file in MB
 #      totalSizeLimit: 300  # Maximum total size for all files in a single request in MB
 #    openAI:
 #      fileSizeLimit: 10  # Disables file uploading to the OpenAI endpoint
 #    default:
 #      totalSizeLimit: 20
 #  serverFileSizeLimit: 100  # Global server file size limit in MB
 #  avatarSizeLimit: 2  # Limit for user avatar image size in MB
# rateLimits:
 # fileUploads:
 #   ipMax: 100
 #   ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
 #   userMax: 50
 #   userWindowInMinutes: 60  # Rate limit window for file uploads per user
# registration:
#  socialLogins: ["google", "facebook", "github", "discord", "openid"]

speech:
  tts:
    openai:
      apiKey: '${TTS_API_KEY}'
      model: 'tts-1'
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
 
  stt:
    openai:
      apiKey: '${STT_API_KEY}'
      model: 'whisper-1'

  speechTab:
    conversationMode: true
    advancedMode: true
    speechToText:
      engineSTT: "external"
      languageSTT: "English (US)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: true
      playbackRate: 1.0
      cacheTTS: true

fileConfig:
  endpoints:
    default:
      fileLimit: 5
      fileSizeLimit: 5
      totalSizeLimit: 15



endpoints:
  assistants:
    disableBuilder: false # Disable Assistants Builder Interface by setting to `true`
    pollIntervalMs: 750  # Polling interval for checking assistant updates
    timeoutMs: 180000  # Timeout for assistant operations
    # Should only be one or the other, either `supportedIds` or `excludedIds`
    # supportedIds: ["asst_supportedAssistantId1", "asst_supportedAssistantId2"]
    # excludedIds: ["asst_excludedAssistantId"]
  custom:
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: ["mistral-tiny", "mistral-small", "mistral-medium"]
        fetch: true  # Attempt to dynamically fetch available models
        userIdQuery: false
      titleConvo: true
      titleMethod: "completion"
      titleModel: "mistral-tiny"
      summarize: true
      summaryModel: "mistral-summary"
      forcePrompt: false
      modelDisplayLabel: "Mistral AI"
      addParams:
        safe_prompt: true
      dropParams:
        - "stop"
        - "user"
        - "presence_penalty"
        - "frequency_penalty"
      # headers:
      #    x-custom-header: "${CUSTOM_HEADER_VALUE}"
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: ["nousresearch/nous-capybara-34b","openrouter/auto","nousresearch/nous-capybara-7b","nousresearch/nous-hermes-2-mistral-7b-dpo","google/gemma-7b-it:free","alpindale/goliath-120b","huggingfaceh4/zephyr-7b-beta","openchat/openchat-7b","gryphe/mythomist-7b","openrouter/cinematika-7b","rwkv/rwkv-5-world-3b","recursal/rwkv-5-3b-ai-town","jebcarter/psyfighter-13b","koboldai/psyfighter-13b-2","neversleep/noromaid-mixtral-8x7b-instruct","nousresearch/nous-hermes-llama2-13b","meta-llama/codellama-34b-instruct","phind/phind-codellama-34b","intel/neural-chat-7b","mistralai/mixtral-8x7b-instruct","haotian-liu/llava-13b","nousresearch/nous-hermes-2-vision-7b","meta-llama/llama-2-13b-chat","perplexity/sonar-small-chat","perplexity/sonar-medium-online","perplexity/sonar-medium-chat","perplexity/sonar-small-online","perplexity/sonar-medium-online","mistralai/mistral-large","perplexity/pplx-70b-online","perplexity/pplx-7b-online","perplexity/pplx-7b-chat","perplexity/pplx-70b-chat","meta-llama/llama-2-70b-chat","nousresearch/nous-hermes-llama2-70b","jondurbin/airoboros-l2-70b","migtissera/synthia-70b","teknium/openhermes-2-mistral-7b","teknium/openhermes-2.5-mistral-7b","pygmalionai/mythalion-13b","undi95/remm-slerp-l2-13b","xwin-lm/xwin-lm-70b","gryphe/mythomax-l2-13b-8k","undi95/toppy-m-7b","alpindale/goliath-120b","lizpreciatior/lzlv-70b-fp16-hf","neversleep/noromaid-20b","01-ai/yi-34b-chat","01-ai/yi-34b","01-ai/yi-6b","togethercomputer/stripedhyena-nous-7b","togethercomputer/stripedhyena-hessian-7b","mistralai/mixtral-8x7b","cognitivecomputations/dolphin-mixtral-8x7b","nousresearch/nous-hermes-yi-34b","anthropic/claude-2","anthropic/claude-2.0","anthropic/claude-instant-v1","anthropic/claude-instant-v1-100k","mancer/weaver","open-orca/mistral-7b-openorca","gryphe/mythomax-l2-13b"]
        fetch: false
      titleConvo: true
      titleModel: "gpt-3.5-turbo"
      summarize: false
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"
      dropParams:
        - "stop"
    #groq
    - name: "groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
            'llama3-70b-8192',
            'llama3-8b-8192',
            'llama2-70b-4096',
            'mixtral-8x7b-32768',
            'gemma-7b-it',
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      summarize: false
      summaryModel: "mixtral-8x7b-32768"
      forcePrompt: false
      modelDisplayLabel: "groq"

   
